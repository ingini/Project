import boto3
import time
import os
import json
import traceback
import signal
from timeout import LambdaTimeoutException
from pytz import timezone
from datetime import datetime

sqs = boto3.client('sqs')
ssm = boto3.client('ssm', region_name='ap-northeast-2')
s3_resource = boto3.client('s3', region_name='ap-northeast-2')
now_time = datetime.now(timezone('Asia/Seoul'))

working_dir = '/tmp'

def timeout_handler(_signal, _frame):
    raise LambdaTimeoutException('Time limit exceeded')

signal.signal(signal.SIGALRM, timeout_handler)

def lambda_handler(event, context):
    try:
        
        signal.alarm(int(context.get_remaining_time_in_millis() / 1000) - 1)

        # hm-datalake-prestaging.ver01
        json_download_bucket = event['Records'][0]['s3']['bucket']['name']
        # json_download_bucket = 'hm-datalake-prestaging.ver01'

        # raw/raidea/peopleCar/json_append/bookings/yy=2022/mm=09/dd=05/bookings-20220905_171510.json
        json_download_key = str(event['Records'][0]['s3']['object']['key'].replace('%3D', '='))
        
        if not 'yy=' in json_download_key:
            print('no partition in {}, skip'.format(json_download_key))
            return {
                'body': json.dumps('no partition')
            }


        # bookings-20220905_120000.json => bookings
        collection_name = json_download_key.rsplit('/', 1)[1].split('-')[0]

        # remove partition
        # raw/raidea/peopleCar/json_upsert_new/bookings/yy=2022/mm=09/dd=05/bookings-20220905_120000.json => raw/raidea/peopleCar/json_upsert_new/bookings
        previous_json_file_key = '{}/{}.json'.format(json_download_key.rsplit('/', 4)[0], collection_name)
        upserted_json_file_key = previous_json_file_key

        upserted_json_dict = {}
        previous_json_file_path = '{}/previous_{}.json'.format(working_dir, collection_name)
        new_json_file_path = '{}/new_{}.json'.format(working_dir, collection_name)
        upserted_json_file_path = '{}/upserted_{}.json'.format(working_dir, collection_name)

        print(previous_json_file_key, '=>', previous_json_file_path)
        print(json_download_key, '=>', new_json_file_path)

        s3_resource.download_file(json_download_bucket, previous_json_file_key, previous_json_file_path)
        s3_resource.download_file(json_download_bucket, json_download_key, new_json_file_path)
        
        print('done downloading previous json, collection name = ', collection_name)

        with open(upserted_json_file_path, 'w', encoding='utf8') as upserted_json_file:
            # read new json and write all
            with open(new_json_file_path, 'r', encoding='utf8') as new_json_file:
                for j in new_json_file:
                    document = json.loads(j)                    
                    id = document['_id']
                    if '$oid' in id:
                        id = document['_id']['$oid']
                    upserted_json_dict[id] = document
                    upserted_json_file.writelines(j)

            # read old json and write only not in new json
            with open(previous_json_file_path, 'r', encoding='utf8') as old_json_file:
                for j in old_json_file:
                    document = json.loads(j)
                    id = document['_id']
                    if '$oid' in id:
                        id = document['_id']['$oid']
                    if id not in upserted_json_dict:
                        upserted_json_file.writelines(j)

        print('done upserting new json, collection name = ', collection_name)

        s3_resource.upload_file(upserted_json_file_path, json_download_bucket, upserted_json_file_key)
        print(upserted_json_file_path, '=>', upserted_json_file_path)
        print('done uploading upserted json, collection name = ', collection_name)
        
        os.remove(previous_json_file_path)
        os.remove(new_json_file_path)
        os.remove(upserted_json_file_path)

        signal.alarm(0)
        
        return {
            'body': json.dumps('success')
        }
        
    except LambdaTimeoutException as e:
        msg = sqs.send_message(QueueUrl="https://sqs.ap-northeast-2.amazonaws.com/284145144652/Lambda-Daily-Error-Report", MessageBody="Timeout,{},{}".format(context.function_name, context.aws_request_id))
        return {'statusCode': 400, 'body': str(e)}
    except Exception as e:
        traceback.print_exc()
        msg = sqs.send_message(QueueUrl="https://sqs.ap-northeast-2.amazonaws.com/284145144652/Lambda-Daily-Error-Report", MessageBody="Error,{},{},{}".format(context.function_name, context.aws_request_id, traceback.format_exc()))
        return {'statusCode': 400, 'body': str(e)} 


if __name__ == '__main__':
    lambda_handler(None, None)